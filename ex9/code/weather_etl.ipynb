{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----+\n",
      "|    station|    date|tmax|\n",
      "+-----------+--------+----+\n",
      "|CA004016322|20161203|-0.5|\n",
      "|CA001096629|20161203| 1.7|\n",
      "|CA008403399|20161203|-0.2|\n",
      "|CA006016529|20161203|-5.7|\n",
      "|CA001175122|20161203| 2.0|\n",
      "|CA003075601|20161203| 2.1|\n",
      "|CA001035614|20161203| 7.5|\n",
      "|CA001160515|20161203| 3.6|\n",
      "|CA003051R4R|20161203| 3.8|\n",
      "|CA006010740|20161203|-5.7|\n",
      "|CA003014195|20161203| 3.1|\n",
      "|CA007093714|20161203|-9.1|\n",
      "|CA00401HP5R|20161203| 1.1|\n",
      "|CA00707DBD4|20161203|-0.4|\n",
      "|CA008205774|20161203| 4.0|\n",
      "|CA003076069|20161203|-0.9|\n",
      "|CA001018935|20161203|10.0|\n",
      "|CA008204909|20161203| 4.1|\n",
      "|CA004010879|20161203|-1.2|\n",
      "|CA001184791|20161203| 2.4|\n",
      "+-----------+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import sys\n",
    "from pyspark.sql import SparkSession, functions, types\n",
    "\n",
    "spark = SparkSession.builder.appName('weather ETL').getOrCreate()\n",
    "\n",
    "assert sys.version_info >= (3, 4) # make sure we have Python 3.4+\n",
    "assert spark.version >= '2.1' # make sure we have Spark 2.1+\n",
    "\n",
    "observation_schema = types.StructType([\n",
    "    types.StructField('station', types.StringType(), False),\n",
    "    types.StructField('date', types.StringType(), False),\n",
    "    types.StructField('observation', types.StringType(), False),\n",
    "    types.StructField('value', types.IntegerType(), False),\n",
    "    types.StructField('mflag', types.StringType(), False),\n",
    "    types.StructField('qflag', types.StringType(), False),\n",
    "    types.StructField('sflag', types.StringType(), False),\n",
    "    types.StructField('obstime', types.StringType(), False),\n",
    "])\n",
    "\n",
    "\n",
    "def main():\n",
    "    in_directory = sys.argv[1]\n",
    "    out_directory = sys.argv[2]\n",
    "    in_directory = \"weather-1\"\n",
    "    out_directory = \"output\"\n",
    "    weather = spark.read.csv(in_directory, schema=observation_schema)\n",
    "    filtered_weather = weather.where(\n",
    "        (weather.qflag.isNull()) &\n",
    "        (weather.station.startswith(\"CA\")) &\n",
    "        (weather.observation == 'TMAX')\n",
    "    )\n",
    "    cleaned_data = filtered_weather.select(\n",
    "        filtered_weather.station, \n",
    "        filtered_weather.date,\n",
    "        (filtered_weather.value / 10).alias(\"tmax\")\n",
    "    )\n",
    "#     k = weather.where(\n",
    "\n",
    "    cleaned_data.show()\n",
    "    # TODO: finish here.\n",
    "#     weather.show()\n",
    "    cleaned_data.write.json(out_directory, compression='gzip', mode='overwrite')\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
